**从调试输出看**，梯度一直为 0，说明你的攻击损失对 δ 根本没有梯度信号。原因在于：

1. Margin/Score/Step 这三项都是基于 logits 计算的，而 logits 是通过  
   ```python
   inputs = processor(x_adv, …)
   logits = model(inputs).logits
   ```  
   得到的。可惜 Hugging Face 的 `processor.feature_extractor` 在内部用的是 numpy（或非 PyTorch）操作来做归一化、分帧等预处理，这部分被包裹在 `torch.no_grad()` 或干脆不支持反向传播，一旦你把 waveform 交给 `processor`，后面的梯度链就被切断了。

2. 你在迭代里又改用 `x_adv.unsqueeze(0)` 直接送给 model，这确实绕过了 processor，但 Wav2Vec2 模型本身也要先对 waveform 做 conv‐feature 抽取，如果你在脚本里把它放到 `model.eval()` 并且没有显式开启 `model.feature_extractor` 的反向传播（它默认不 require_grad），那么特征提取层也不起梯度。

简单说：**攻击失效的核心是“预处理 + 模型特征抽取”两个环节都没有给 δ 留下反向通道，所以梯度始终为零。**

修复思路有两条路径（任选其一或合并）：

1. 让预处理／特征抽取全程在 PyTorch 中支持梯度  
   - 不调用 `processor.feature_extractor` 的 numpy 逻辑，而是直接把 `x_adv` 送给模型内部的 `feature_extractor`（它是 `nn.Conv1d` 系列），并且把这些层都设置 `requires_grad=True`  
   - 示例：  
     ```python
     # 关闭外部 processor
     input_values = x_adv.unsqueeze(0)  # [1,L]
     # 确保 conv feature extractor 支持梯度
     for p in model.feature_extractor.parameters():
         p.requires_grad = False  # 冻结权重，但 conv 层 forward 会保留梯度到输入
     logits = model(input_values).logits
     ```
   - 这样就能把 loss 的梯度真正传到 `input_values`（也就是 x_adv），再流到 δ。

2. 自己实现一套可微分的预处理  
   - 用 PyTorch 实现 waveform normalization、padding、特征抽取（可参考源码里的卷积结构）  
   - 把这段代码写到脚本里，确保全程在 PyTorch 计算图里，不再用 numpy

实际最省事的是方案 1：把处理直接交给模型的 `feature_extractor`（它是 Conv1d），并保证 `input_values` 的反向通道没被任何 `no_grad` 或外部 numpy 层截断。  

请在你的主循环里删除所有对 `processor` 的调用，只保留直接 `input_values = x_adv.unsqueaudio_adversarial_examplesze(0)`，并检查 `model.feature_extractor` 下的参数：

```python
# 在加载模型后：
for module in model.feature_extractor.modules():
    if isinstance(module, torch.nn.Conv1d):
        module.weight.requires_grad = False  # 冻结权重
        module.bias.requires_grad = False
# 这时 Conv1d 层的 forward 会把 grad 传回 input_values
```

然后再跑一遍 debug，你应该会看到 `delta.grad.norm` 从 0 变成非零，再接着就能更新 δ 了。  

这里先采用 方案1 ，绕过 HF 的 numpy 预处理，直接让音频走到模型内部的 PyTorch conv 特征提取层，从而保证这条路径对输入保持可导

1. 在加载模型后冻结 conv 层参数  
   ```python
   # model = Wav2Vec2ForCTC.from_pretrained(…)
   for p in model.feature_extractor.parameters():
       p.requires_grad = False
   ```
   这样做不会改变模型输出，但能保证它的前几层（Conv1d）在 forward 时，会把梯度传递到它们的输入张量上。
   `requires_grad = False` 只表示不需要给它自己算梯度，并不会阻断梯度从输出传到它的输入
   因此这里相当于冻结卷积核，不让它们被更新，但是可以计算音频输入的梯度

2. 攻击循环中不再调用 processor，直接做  
   ```python
   x_adv = x_orig + delta           # delta.requires_grad=True
   input_values = x_adv.unsqueeze(0)  # [1, L]
   logits = model(input_values).logits
   ```
   因为 Conv1d 的实现是纯 PyTorch，当你对 `logits` 反向时，梯度会一路从 logits→卷积→`input_values`→`delta`。

3. 这样 `loss.backward()` 就能在 `delta.grad` 上看到非零值，后续 `optimizer.step()` 才能更新扰动。

为什么成立？  
- HF 的 `Wav2Vec2Processor` 内部归一化、分帧等都是 numpy 操作或包在 `no_grad` 里，断开了计算图；  
- 而模型自带的 `feature_extractor` 是一组 `nn.Conv1d`，对其输入默认保留梯度；只要不在它外面再做 `torch.no_grad()`，就能把梯度“传回”到输入张量。

在之前 audio_adversarial_examples 的实现里，他们也是**自己用 PyTorch（或 torchaudio）实现完整的特征抽取流程**，不落回外部 numpy，这样才能完整保持从对抗损失到原始 waveform 的计算图，才能在攻击时拿到梯度并更新输入。

原先使用 `processor`，内部会把 waveform 变成 float、做归一化、分帧、拼 batch，再转给模型。
这些步骤往往是 numpy 或包在 torch.no_grad() 里，断开了对原始 waveform（δ）的计算图，梯度无法回传到 δ。